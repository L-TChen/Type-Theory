%! TEX program = xelatex
%! TEX root = lecture1_slide.tex
\title{$\lambda$-Calculus}
\subtitle{Untyped $\lambda$-Calculus}
\begin{document}

{\usebackgroundtemplate{\includegraphics[width=\paperwidth]{banner.pdf}}
\begin{frame}\maketitle\end{frame}}

\begin{frame}[fragile]{Assessment guidelines}
  \begin{description}
    \item[Deadline] 17:00, 10 Aug
    \item[Assessment] 
      \begin{description}
        \item[Assignment] (15\%)
        \item[Exam] (100\%)
      \end{description}
    \item[Email] \texttt{liang.ting.chen.tw(at)gmail(dot)com}
  \end{description}

  \textbf{Please follow the instructions below.}

  \begin{enumerate}
    \item Use A4 paper.
    \item Write down your name and student id. 
    \item Be clear and brief.
    \item Submit assignments in person or by email as \alert{PDF} with 
      \begin{description}
        \item[subject] \texttt{[FLOLAC] PL HW\%x\%}
        \item[attachment] \texttt{PL-HW\%x\% - \%STDNO\% - \%NAME\%.pdf}
        \item[body] (optional)
      \end{description}
  \end{enumerate}
\end{frame}

\section{Untyped $\lambda$-Calculus: Statics}


\begin{frame}{$\lambda$-calculus: Term}

\begin{definition}[{Syntax of $\lambda$-calculus}]
  Given a set $V$ of variables, 
  the term formation judgement is defined by
  \begin{description}
     \item[Variable]
       \hfill
       \begin{prooftree}
         \AXC{$x$ is in $V$}
         \RightLabel{(var)}
         \UIC{$x \quad \term_V$}
       \end{prooftree}
 
    \item[Application]
      of $M$ to the argument $N$
      \hfill
      \begin{prooftree}
        \AXC{$M \quad \term_V$}
        \AXC{$N \quad \term_V$}
        \RightLabel{(app)}
        \BIC{$M \; N \quad \term_V$}
      \end{prooftree}

    \item[Abstraction]
      with an argument $x$ and a function body $M$
      \hfill
      \begin{prooftree}
        \AXC{$M \quad \term_V$}
        \AXC{$x$ is in $V$}
        \RightLabel{(abs)}
        \BIC{$\lambda \alert{x}.\, M \quad \term_V$}
      \end{prooftree}
  \end{description}
\end{definition}
 
\end{frame}


\begin{frame}{An Example}
  The judgement
\[
  \fbox{$\lambda p.\, \lambda a.\, \lambda b.\, (p\;a)\; b \quad \term_V$}
\]
is justified by the following derivation
  \begin{prooftree}
    \footnotesize
    \AXC{$p$ is in $V$}
    \UIC{$p \quad \term_V$}
    \AXC{$a$ is in $V$}
    \UIC{$a \quad \term_V$}
    \BIC{$p\;a \quad \term_V$}
    \AXC{$b$ is in $V$}
    \UIC{$b \quad \term_V$}
    \BIC{$(p\;a)\;b \quad \term_V$}
    \AXC{$b$ is in $V$}
    \BIC{$\lambda b.\, (p\;a)\;b \quad \term_V$}
    \AXC{$a$ is in $V$}
    \BIC{$\lambda a.\, \lambda b.\, (p\;a)\; b \quad \term_V$}
    \AXC{$p$ is in $V$}
    \BIC{$\lambda p.\, \lambda a.\, \lambda b.\, (p\;a)\; b \quad \term_V$}
  \end{prooftree}
  N.B.\ brackets `(' and `)' are not parts of terms and they are used only to group a term.
\end{frame}

\begin{frame}{More Example and non-examples}
  \begin{enumerate}
    \item $(x\;y)\;z$
    \item $x\;(y\; z)$
    \item $\lambda x.\, y$
    \item $\lambda x.\, x$
    \item $\lambda s.\,(\lambda z.\, (s \;z))$
    \item $\lambda a.\,(\lambda b.\, (a\;(\lambda c.\, a\; b)))$
    \item $(\lambda x.\, x)\;(\lambda y.\, y)$
  \end{enumerate}
  The following are NOT examples
  \begin{enumerate}
    \item $\lambda (\lambda x.\, x).\, y$
    \item $\lambda x. $
    \item $\lambda.\, x$
    \item $\dots$
  \end{enumerate}
\end{frame}

\begin{frame}{Conventions}
  \begin{description}
    \item[Consecutive abstractions]
      \[
        \lambda x_1\,x_2\,\ldots x_n.\, M \equiv \lambda x_1.\,(\lambda x_2.\,(\ldots (\lambda x_n.\, M)\ldots))
      \]
    \item[Consecutive applications]
      \[
        M_1\;M_2\; M_3\; \dots\;M_n \equiv (\dots((M_1\;M_2)\;M_3) \dots )\; M_n
      \]
    \item[Function body extends as far right as possible]
      \[
        \lambda x.\, M\;N \defeq \lambda x.\,(M\; N)
      \]
      instead of $(\lambda x.\,M)\; N$.
  \end{description}
  For example, 
      $\lambda x_1.\,(\lambda x_2.\, x_1) \equiv \lambda x_1\,x_2.\,x_1$
      and
      $\alert{x\;y\;z}$ means $\alert{(x\; y)\;z}$. 

\end{frame}

\begin{frame}{Examples}
  \begin{enumerate}
    \item $(x\;y)\;z \equiv x\;y\;z$
    \item $\lambda s.\,(\lambda z.\, (s \;z)) \equiv \lambda s\,z.\, s\;z$
    \item $\lambda a.\,(\lambda b.\, (a\;(\lambda c.\, a\; b))) \equiv \lambda a\,b.\, a\;(\lambda c.\, a\;b)$
    \item $(\lambda x.\, x)\;(\lambda y.\, y) \equiv (\lambda x.\, x)\;\lambda y.\, y$
  \end{enumerate}
\end{frame}

\begin{frame}{Meta-language and object-language}
  \begin{itemize}
    \item \emph{Meta-language} is the language we use to describe the object of
      study. E.g. English, or naive set theory. 
    \item \emph{Object-language} is the object of study. E.g., arithmetic
      expressions and $\lambda$-terms.
  \end{itemize}
  Naming a function is \emph{not} supported in $\lambda$-calculus, so
  the following
    \[
      \mathtt{id} \defeq \lambda x.\, x
    \]
  happens in the meta-language. 
  \begin{enumerate}
    \item $\mathtt{id}$ is a symbol different from `$\lambda x.\,x$' in the meta-language.
    \item $\mathtt{id}$ and $\lambda x.\, x$ are \emph{syntactically equivalent} denoted by
      \[
        \mathtt{id} \equiv \lambda x.\, x
      \]
  \end{enumerate}
\end{frame}

\begin{frame}
  \begin{example}[Identity function]
    \[
      \mathtt{id} \defeq \lambda x.\, x
    \]
  \end{example}

  \begin{example}[Projections]
    \[
      \mathtt{fst} \defeq \lambda x.\, \lambda y.\, x
      \quad\text{and}\quad \mathtt{snd} \defeq \lambda x.\, \lambda y.\, y
    \]
  \end{example}
  Remember that there are only three constructs in $\lambda$-calculus.
  For convenience, we normally use a surface language to generate terms in the object-language.
%  \begin{example}[Church encoding of Natural numbers]
%    \begin{align*}
%      &\bc_{0}   &&\defeq \;&& \lambda f\,x.\, x \\
%      &\bc_{1} &&\defeq \;&& \lambda f\,x.\, f\,x \\
%      &\bc_{2} &&\defeq \;&& \lambda f\,x.\, f\,(f\,x) \\
%      &\bc_{3} &&\defeq \;&& \lambda f\,x.\, f\,(f\,(f(\,x))) \\
%      && \vdots 
%    \end{align*}
%  \end{example}
\end{frame}

\begin{frame}{$\alpha$-equivalence, informally}
  \begin{definition}
    Two terms $M$ an $N$ are \alert{$\alpha$-equivalent} 
    \[
      M =_\alpha N
    \]
    if variables \emph{bound} by abstractions can be renamed to derive the same term. 
  \end{definition}
  \begin{example}
    \begin{enumerate}
      \item $\lambda x.\, x$ and $\lambda y.\, y$ are distinct $\lambda$-terms but $\lambda x.\, x
        =_\alpha \lambda y.\, y$. 
      \item $\lambda x.\, \lambda y.\, y =_\alpha 
        \lambda z.\, \lambda y.\, y$. 
      \item $\lambda x.\, \lambda y.\, x \mathrel{\neq}_\alpha
        \lambda x.\, \lambda y.\, y$. 
    \end{enumerate}
  \end{example}
  
  $\alpha$-equivalent terms are \emph{programs of the same structure modulo the name of bound variables}.
\end{frame}

\begin{frame}{Evaluation, informally}
  The \alert{evaluation} of $\lambda$-calculus is of this form 
  \[
    \fbox{$\cdots\underbrace{(\lambda x.\, M)\,N}_{\beta\text{-redex}} \cdots$} \longrightarrow_{\beta 1}
    \fbox{$\cdots \underbrace{M\;\subst{N}{x}}_{\text{substitution of $N$ for $x$ in $M$}} \cdots$}
  \]

  For example, $(\lambda x.\, x +1)\;3 \to 3 + 1$.
  \mode<presentation>{\vfill}
  How to evaluate the following terms? 
  \begin{enumerate}
    \item $(\lambda x.x)\,z$
    \item $(\lambda x\, y.\,x)\,y$
    \item $(\lambda y\, y.\,y)\,x$
  \end{enumerate}
\end{frame}


\begin{frame}{Structural recursion: Free variables}
\begin{definition}
  The set $\FV$ of free variables of a term $M$ is inductively defined by
  \begin{align*}
    \FV \colon  \term_V & \to \mathcal{P}(V) \\
    \FV(x) & = \{x\} \\
    \FV(\lambda x.\, M) & = \FV(M) - \{x\} \\
    \FV(M\;N) & = \FV(M) \cup \FV(N)
  \end{align*}
\end{definition}
\begin{definition}
  \begin{enumerate}
    \item A variable $y$ in $M$ is \alert{free} if $y \in \FV(M)$.
    \item A $\lambda$-term~$M$ is \alert{\emph{closed}} if $\FV(M) = \emptyset$. 
  \end{enumerate}
\end{definition}

\end{frame}

\begin{frame}{Exercise}
  The set of free variables of a term is calculated by definition readily, e.g., 
    \begin{align*}
      \FV(x\;(\lambda y.\, y)\;z) & = \FV(x\;(\lambda y.\, y)) \cup \FV(z) \\ 
                                  & = \FV(x) \cup (\FV(y) - \{y\}) \cup \{z\} \\
                                  & = \{x\} \cup (\{y\}-\{y\}) \cup \{z\} \\
                                  & = \{x, z\}
    \end{align*}

  Calculate the set of free variables of following terms:
  \begin{enumerate}
    \item $x\;(y\; z) $
    \item $\lambda x.\, y$
    \item $\lambda x.\, x$
    \item $\lambda s\,z.\, s \;z$
    \item $(\lambda x.\, x)\;\lambda y.\, y$
  \end{enumerate}
\end{frame}

\begin{frame}{Exercise: Height}
  The height of a term is given informally as follows:
  \begin{enumerate}
    \item the height of a variable is zero;
    \item the height of an application is the maximum of the heights of its subterms plus 1;
    \item the height of an abstraction is the height of its body plus 1.
  \end{enumerate}
  
  Define the height function $h\colon \term_V \to \mathbb{N}$ inductively.
\end{frame}

\section{Untyped $\lambda$-Calculus: Substitution}

\begin{frame}{Substitution}
   A \alert{substitution} is a process of replacing \emph{free} variables by
   another terms on the meta-level. Hence, a substitution of $N$ for a free
   variable $x$ is a function
   \[
     {\_}\subst{N}{x}\colon \term_V \to \term_V
   \]

   The name of a variable does not matter but its location does.
   \begin{enumerate}
     \item bound variables should remain bound after substitution.
     \item free variables which are not $x$ should remain free after substitution.
   \end{enumerate}

   Concretely, we want to avoid ...
  \begin{enumerate}
    \item $(\lambda y.\,y)[x/y] \equiv (\lambda y.\, x)$
    \item $(\lambda y.\, x)[y/x] \equiv (\lambda y.\, y)$ 
  \end{enumerate}
   
  
\end{frame}
  
\begin{frame}{Naive substitution I}
    For $x \in V$ and $L : \term_V$, the substitution of $L$ for $x$ is
    defined by
    \begin{align*}
      x\subst{L}{x} & = L \\
      y\subst{L}{x} & = y & \text{if $x \neq y$} \\
      (M\;N)\subst{L}{x}& = M\subst{L}{x} \; N\subst{L}{x} \\
      (\lambda y.\, M)\subst{L}{x} & = \lambda y.\, M \subst{L}{x}
    \end{align*}

    A bound variable may become free after substitution, e.g.,\  
    \[
      (\lambda x.\, x)\subst{y}{x} = \lambda x.\, y
    \]
    so this is not the one we want.
\end{frame}
\begin{frame}{Naive substitution II}
    For $x \in V$ and $L : \term_V$, the substitution
    of $L$ for $x$ is defined by
    \begin{align*}
      x\subst{L}{x} & = L \\
      y\subst{L}{x} & = y && \text{if $x \neq y$} \\
      (M\,N)\subst{L}{x} & = M\subst{L}{x}\; N\subst{L}{x} \\
      (\lambda y.\, M)\subst{L}{x} & = \lambda y.\, M\subst{L}{x} && \text{if $x \neq y$} \\
      (\lambda y.\, M)\subst{L}{x} & = \lambda y.\, M && \text{if $x = y$} 
    \end{align*}

    A variable may be captured by an abstraction after substitution, e.g.,
    \[
      (\lambda x. y)\subst{x}{y} = \lambda x.\, x
    \]
    so again it is not the desired definition.
\end{frame}


\begin{frame}{Capture-avoiding substitution}
  \begin{definition}
    Capture-avoiding substitution\footnote{Sigh, this definition is still not rigorous.} of $L$ for the \alert{free occurrences} of $x$ is a
    \emph{partial} function $\_\subst{L}{x}\colon \term_V \to \term_V$ defined by
    \begin{align*}
      x\subst{L}{x} & = L \\
      y\subst{L}{x} & = y && \text{if $x \neq y$} \\
      (M\, N)\subst{L}{x} & = M\subst{L}{x}\; N\subst{L}{x} \\
      (\lambda x.\, M)\subst{L}{x} & = \lambda x.\, M \\
      (\lambda y.\, M)\subst{L}{x} & = \lambda y.\, M\subst{L}{x}                                 &&\text{if $x \neq y$ and $y \not\in \FV(L)$}
    \end{align*}
  \end{definition}

\end{frame}

\begin{frame}{Renaming of bound variables}
\begin{definition}[Freshness]
  A variable $y$ is \alert{fresh} for $L$ if $y \notin \FV(L)$.  
\end{definition}

If a variable $y$ is \emph{fresh} for $M$, the bound variable $x$ of~$\lambda
x.\, M$ can be renamed to~$y$ without changing the meaning. 
  \mode<presentation>{\vfill}
\begin{definition}[$\alpha$-conversion]
  \emph{$\alpha$-conversion} is an judgement $M \to_\alpha N$ between terms defined by
  \begin{prooftree}
    \AXC{$y$ is fresh for $M$}
    \UIC{$\lambda x.\, M \longrightarrow_\alpha \lambda y.\, M\subst{y}{x}$}
  \end{prooftree}
\end{definition}

Yet, $M\;(\lambda x.\, x) \longrightarrow_\alpha M\;(\lambda y.\, y)$ does
not follow by definition, so we introduce a new judgement to allow
$\alpha$-conversion in any subterm of a term.

\end{frame}

\begin{frame}{$\alpha$-equivalence}
  \begin{definition}
  \begin{multicols}{2}
    \begin{prooftree}
      \AXC{$x$ is a variable}
      \UIC{$x =_\alpha x$}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$M_1 \mathrel{\to_\alpha} M_2$}
      \UIC{$M_1 \mathrel{=_\alpha} M_2$}
    \end{prooftree}
%    \begin{prooftree}
%      \AXC{$M_1 \mathrel{=_\alpha} M_2$}
%      \UIC{$M_2 \mathrel{=_\alpha} M_1$}
%    \end{prooftree}
%    \begin{prooftree}
%      \AXC{$M_1 \mathrel{=_\alpha} M_2$}
%      \AXC{$M_2 \mathrel{=_\alpha} M_3$}
%      \BIC{$M_1 \mathrel{=_\alpha} M_3$}
%    \end{prooftree}
%    \begin{prooftree}
%      \AXC{$M_1 \mathrel{=_\alpha} M_2$}
%      \UIC{$(M_1\,N) \mathrel{=_\alpha} (M_2\,N)$}
%    \end{prooftree}
    \begin{prooftree}
      \AXC{$M_1 \mathrel{=_\alpha} M_2$}
      \AXC{$N_1 \mathrel{=_\alpha} N_2$}
      \BIC{$M_1\;N_1 \mathrel{=_\alpha} M_2\;N_2$}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$M_1 \mathrel{=_\alpha}M_2$}
      \UIC{$\lambda x.\, M_1 \mathrel{=_\alpha} \lambda x.\, M_2$}
    \end{prooftree}
  \end{multicols}
\end{definition}

$\alpha$-equivalence is an \emph{equivalence}, i.e.
\begin{description}
  \item[reflexivity] $M =_\alpha M$ for any term M;
  \item[symmetry] $N =_\alpha M$ if $M =_\alpha N$;
  \item[transitivity] $L =_\alpha N$ if $L =_\alpha M$ and $M =_\alpha N$. 
\end{description}
All of these can be proved by induction on the derivation of $M =_\alpha M$.

\end{frame}

%\begin{frame}{Proof of reflexivity}
%      By induction on the formation of $M$.
%      \begin{enumerate}
%        \item $M = x$ for some $x \in V$. Then, by definition $x =_\alpha
%          x$ holds.
%
%        \item $M = M_1\;M_2$. Then, by induction hypothesis, we have
%          derivations $D_1$ and $D_2$ for $M_1 =_\alpha M_1$ and $M_2
%          =_\alpha M_2$ respectively. Therefore, we have the desired derivation 
%          \begin{prooftree}
%            \AXC{$\vdots$}
%            \RightLabel{$D_1$}
%            \UIC{$M_1 \mathrel{=_\alpha} M_1$}
%            \AXC{$\vdots$}
%            \RightLabel{$D_2$}
%            \UIC{$M_1 \mathrel{=_\alpha} M_2$}
%            \BIC{$M_1\;M_2 \mathrel{=_\alpha} M_1\;M_2$}
%          \end{prooftree}
%        \item $M = \lambda x.\, M'$. By induction hypothesis, we have a derivation $D$ for $M' =_\alpha M'$. Hence, 
%          \begin{prooftree}
%            \AXC{$\vdots$}
%            \RightLabel{$D$}
%            \UIC{$M' \mathrel{=_\alpha}M'$}
%            \UIC{$\lambda x.\, M' \mathrel{=_\alpha}\lambda x.\, M'$}
%            
%          \end{prooftree}
%      \end{enumerate}
%\end{frame}

%\begin{frame}{Proof of symmetry}
%  By induction on the derivation $D$ of $M =_\alpha N$. The only interesting
%  case is that $D$ is derived from an $\alpha$-conversion, i.e.
%  \[
%    \lambda x.\, M' \to_\alpha \lambda y.\, M'\subst{y}{x}
%  \]
%  and $y$ is fresh for $M'$. We know that $x \not\in \FV(M'\subst{y}{x})$ since 
%  the substitution $\subst{y}{x}$ replaces\footnote{
%    We actually need to show that $x \not\in \FV(M[y/x])$ whenever $\FV(M[y/x])$ is defined.}
%  the free variable $x$ by $y$.  Therefore, we have $\lambda x.\,
%  M'\subst{y}{x}\subst{x}{y} \equiv \lambda x.\, M'$. It follows that 
%  \[
%    \lambda y. M'\subst{y}{x} \to_\alpha \lambda x. M'
%  \]
%  Hence, $N =_\alpha M$.
%\end{frame}
%
%\begin{frame}{Proof of transitivity}
%  By induction on the derivations $D_1$ and $D_2$ of $L =_\alpha M$ and $M =_\alpha N$ respectively. The interesting case is when $D_i$'s are given by $\alpha$-conversion
%  \[
%    \lambda x.\,M' \to_\alpha \lambda y.\,M'\subst{y}{x} \to_\alpha \lambda z.\, M'\subst{y}{x}\subst{z}{y}. 
%  \]
%  
%  It follows that 
%  \[
%    \lambda x.\,M' \to_\alpha \lambda z.\,M'\subst{z}{x}
%  \]
%  where the freshness condition clearly holds (why?)
%  and also that
%  \[
%    M'\subst{y}{x}\subst{z}{y} \equiv M'\subst{z}{x}.
%  \]
%  Hence, transitivity holds for this case.
%\end{frame}
\begin{frame}
  \begin{example}
    \[
      (\lambda y.\, y)\;(\lambda x.\, x) =_\alpha (\lambda
    x.\,x)\;(\lambda y.\,y) 
    \]
  \end{example}

  Why? We use the fact that $=_\alpha$ is an equivalence!
  \begin{proof}
  \begin{prooftree}
    \AXC{}
    \UIC{$\lambda x.\, x \to_\alpha \lambda y.\, x\subst{y}{x}$}
    \UIC{$\lambda x.\, x =_\alpha \lambda y.\, y$}
    \UIC{$(\lambda y.\, y)\; (\lambda x.\, x) =_\alpha (\lambda y.\, y)\; (\lambda y.\, y)$}
    \AXC{}
    \UIC{$\lambda y.\, y \to_\alpha \lambda x.\, y\subst{x}{y}$}
    \UIC{$\lambda y.\, y =_\alpha \lambda x.\, x$}
    \UIC{$(\lambda y.\, y)\; (\lambda y.\, y) =_\alpha (\lambda x.\, x)\; (\lambda y.\, y)$}
    \BIC{$(\lambda y.\, y)\; (\lambda x.\, x) =_\alpha (\lambda x.\, x)\; (\lambda y.\, y)$}
  \end{prooftree}
  \end{proof}
\end{frame}

\begin{frame}{Exercise}

Which of the following pairs are $\alpha$-equivalent? Why?
\begin{enumerate}
  \item $x$ and $y$
  \item $\lambda x\,y.\, y$ and $\lambda z\,y.\, y$
  \item $\lambda x\,y.\, x$ and $\lambda y\,x.\, y$
  \item $\lambda x\,y.\, x$ and $\lambda x\,y.\, y$
\end{enumerate}

  \mode<presentation>{\vfill}
\begin{block}{Convention}
  $\alpha$-equivalent terms are \alert{identified}. 
\end{block}

In the following development, we do not distinguish $M$ and $N$ if $M
=_\alpha N$ at all. Feel free to rename any bound variable whenever
convenient.

\end{frame}

\section{Untyped $\lambda$-Calculus: Dynamics}
%
%
%\begin{frame}{$\eta$-conversion}
%  Pointy style is \emph{assumed} to be equivalent to point-free style. 
%  \begin{description}
%    \item[$\eta$-reduction]
%      $\lambda x.\,(M\,x) \longrightarrow_\eta M$
%    \item[$\eta$-expansion]
%      $M \longrightarrow_\eta \lambda x.\,(M\,x) $
%      where $x$ is fresh for $M$.
%  \end{description}
%  \mode<presentation>{\vfill}
%  $\eta$-equivalence is a form of \emph{extensionality} limited to
%  $\lambda$-terms.
%  \[
%    f = g \iff \forall x.\, f(x) = g(x)
%  \]
%\end{frame}

\begin{frame}{$\beta$-conversion}
\begin{definition}[$\beta$-conversion]
  $\beta$-\emph{conversion} is a judgement $M \longrightarrow_\beta N$ defined by
  \begin{prooftree}
    \AXC{$M\subst{N}{x}$ is defined}
    \UIC{$(\lambda x.\, M)\;N \longrightarrow_{\beta} M\subst{N}{x}$}
  \end{prooftree}
  for any $x$, $M$ and $N$.
\end{definition}

By definition, we can conclude that 
  \begin{align*}
    (\lambda x.\,\lambda y.\,x)\;M
    & \longrightarrow_{\beta}
    (\lambda y.\, x)\subst{M}{x} \\
    & \equiv \lambda y.\, x\subst{M}{x} \equiv \lambda y.\, M \\
  \end{align*}
  but not $((\lambda x\, y.\, x)\; M)\;N \longrightarrow_{\beta} \, (\lambda
  y.\, M)\;N$,
  since the above judgement is defined only for \alert{$\beta$-redexes}.
\end{frame}

\begin{frame}{One-step $\beta$-reduction}

One-step $\beta$-reduction extends $\beta$-conversion to any subterm of a
term.  

\begin{definition}
  The \emph{one-step (full) $\beta$-reduction} is defined inductively by
  \begin{multicols}{2}
    \begin{prooftree}
      \AXC{$M\subst{N}{x}$ is defined}
      \UIC{$(\lambda x.\, M)\;N \onereduce M\subst{N}{x}$}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$M_1 \onereduce M_2$}
      \UIC{$\lambda x.\, M_1 \onereduce \lambda x.\, M_2$}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$M_1 \onereduce M_2$}
      \UIC{$M_1\;N \onereduce M_2\;N$}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$N_1\onereduce  N_2$}
      \UIC{$M\;N_1 \onereduce M\;N_2$}
    \end{prooftree}
  \end{multicols}
\end{definition}
    $((\lambda x\, y.\, x)\; M)\;N \onereduce (\lambda y.\, M)\;N \onereduce M\subst{N}{y}$
\end{frame}

\begin{frame}{Multi-step full $\beta$-reduction}
  It is convenient to represents a sequence
  of $\beta$-reductions
  \[
    M \onereduce M_1 \onereduce \dots \onereduce N
  \]
  by a single judgement $M \reduce N$. 

  \begin{definition}
    The \emph{multi-step (full) $\beta$-reduction} is defined inductively by
    \begin{prooftree}
      \AXC{$\vphantom{M_1}$}
      \RightLabel{($0$-step)}
      \UIC{$M \reduce M$}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$L \onereduce M$}
      \AXC{$M \reduce N$}
      \RightLabel{($n+1$-step)}
      \BIC{$L \reduce N$}
    \end{prooftree}
    
  \end{definition}
\end{frame}

\begin{frame}{$M \reduce N$ is transitive}
  \begin{lemma}
    For every derivations of $L \reduce M$ and $M \reduce N$, there
    is a derivation of $L \reduce N$. 
  \end{lemma}
  We often omit the term ``derivation'' and say ``if $L \reduce M$ and $M \reduce N$ then $L \reduce N$'' instead.
  \begin{proof}
    By induction on the derivation $d$ of $L \reduce M$. 
    \begin{enumerate}
      \item If $d$ is given by (0-step), then $L =_\alpha M$ (by convention).
      \item If $d$ is given by (n+1-step), i.e.\ there exists $M'$ such that
        $L \onereduce M'$ and $M' \reduce M$. By induction hypothesis,
        every derivation $M \reduce N$ gives rise to a derivation of $M' \reduce N$.
        Hence, by (n+1-step), we have a derivation of $L \reduce N$. 
    \end{enumerate}
  \end{proof}
  
\end{frame}
\begin{frame}{$\alpha$-conversion during $\beta$-reduction}

  Renaming of bound variables may need to happen during reduction:
  \begin{align*}
    (\lambda y.\, y\; y)\; (\lambda z\,x.\, z\;x) 
  & \onereduce && (\lambda z\,x.\, z\;x)\; (\lambda z\,x.\, z\;x) \\
  & \onereduce && \lambda x.\, (\lambda z\,x.\, z\;x) \;x  \\
  & =_\alpha   && \lambda x.\, (\lambda z\,y.\, z\;y) \;x  \\
  & \onereduce && \lambda x.\, (\lambda y.\, x\;y)
  \end{align*}
  
  Even worse, we actually need infinitely many variables:
  \[
    (\lambda y.\,y\; s\; y)\; (\lambda t\,z\,x.\, z\; (t\; x)\; z)
  \]
  \begin{exercise*}
    Evaluate the above term.
  \end{exercise*}
\end{frame}

\begin{frame}{Computational meaning}
  Two terms $M$ and $N$ may not have the same structure or even not reducible
  from one to the other, but they may have the same meaning with respect to
  computation.

  \begin{definition}
    $M$ and $N$ have the same \alert{\emph{computational meaning}} if $M =_\beta N$
    which is defined inductively by
    \begin{multicols}{2}
      \begin{prooftree}
        \AXC{$M \onereduce N$}
        \UIC{$M =_\beta N$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{}
        \UIC{$M =_\beta M$}
      \end{prooftree}
      \columnbreak
      \begin{prooftree}
        \AXC{$M =_\beta N$}
        \UIC{$N =_\beta M$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$L =_\beta M$}
        \AXC{$M =_\beta N$}
        \BIC{$L =_\beta N$}
      \end{prooftree}
    \end{multicols}
  \end{definition}
\end{frame}

\begin{frame}{Summary}
  SUMMARISE HERE ALL THE RELATIONS JUST INTRODUCED.
\end{frame}

\section{Programming in $\lambda$-Calculus}
\begin{frame}{Church encoding of boolean values}
  
Boolean and conditional can be encoded as combinators.
  
\begin{description}
  \item[Boolean]
    \begin{align*}
      & \mathtt{True}  && \defeq && \lambda x\,y.\, x \\
      & \mathtt{False} && \defeq && \lambda x\,y.\, y
    \end{align*}

  \item[Conditional]
    \begin{align*}
      \mathtt{if} & \defeq \lambda b\;x\;y.\;b\,x\,y  \\
      \mathtt{if} \;\mathtt{True} \;M\;N &\reduce M \\
      \mathtt{if} \;\mathtt{False}\;M\;N &\reduce N
    \end{align*}
    for any two $\lambda$-terms $M$ and~$N$.
\end{description}

\end{frame}
\begin{frame}[allowframebreaks]{Church Encoding of natural numbers}

  Natural numbers as well as arithmetic operations can be encoded in untyped
  lambda calculus.
  \begin{description}
    \item[Church numerals] 
      \begin{align*}
        &\bc_0 &&\defeq\;&& \lambda f\,x.\, x \\
        &\bc_{1} &&\defeq\;&& \lambda f\,x.\, f\,x \\
        &\bc_{2} &&\defeq\;&& \lambda f\,x.\, f\,(f\,x) \\
        &\bc_{n+1} &&\defeq\;&& \lambda f\,x.\, f^{n+1}\,(x)
      \end{align*}
      where $f^1(x) \defeq f\;x$ and $f^{n+1}(x)  \defeq f\;(f^n(x))$.
    \item[Successor]
      \begin{align*}
        & \mathtt{succ} && \defeq\; && \lambda n.\,\lambda f\,x.\, f\,(n\,f\,x) \\
        & \mathtt{succ}\;\bc_n && \reduce\; && \bc_{n+1}
      \end{align*}
      for any natural number~$n \in \mathbb{N}$.
    \item[Addition]
      \begin{align*}
        & \mathtt{add} && \defeq\; && \lambda n\,m.\,\lambda f\,x.\;
        n\;f\;(m\;f\;x)  \\ & \mathtt{add}\;\bc_{n}\;\bc_{m}\;
                            && \reduce\; && \bc_{n + m}
      \end{align*}

    \item[Conditional]
      \begin{align*}
        & \mathtt{ifz} && \defeq \; \lambda n\;x\;y.\;n\;(\lambda z.\;y)\;x 
        \\
        & \mathtt{ifz}\;\bc_0\;M\;N && \reduce \; M \\
        & \mathtt{ifz}\;\bc_{n+1}\;M\;N && \reduce \; N
      \end{align*}
  \end{description}
\end{frame}

\begin{frame}{Exercise}
  \begin{enumerate}
    \item Define Boolean operations $\mathtt{not}$, $\mathtt{and}$, and $\mathtt{or}$.
    \item Evaluate $\mathtt{succ}\;\bc_0$ and $\mathtt{add}\;\bc_{1}\;\bc_{2}$. 
    \item Define the multiplication $\mathtt{mult}$ over Church numerals.

  \end{enumerate}
\end{frame}
\begin{frame}{General Recursion via self-reference}

  The summation $\sum_{i = 0}^{n} i$ for $n \in \mathbb{N}$ is usually
  described by self-reference in mathematics as follows.
\[
  \mathit{sum}(n) =
    \begin{cases} 
     0 & \text{if } n = 0 \\
     n + \mathit{sum}(n - 1)  & \text{otherwise}.
    \end{cases}
\]
This \alert{cannot} be done in $\lambda$-calculus directly. (Why?)

\begin{block}{Observation}
  If $\mathit{sum}$ is unfolded as many times as it requires, then

\[
  \mathit{sum}(n) =
    \begin{cases} 
     0 & \text{if } n = 0 \\
     1 + \mathit{sum}(0) & n = 1 \\
     2 + \mathit{sum}(1) & n = 2 \\
     \cdots \\
     n + \mathit{sum}(n - 1)  & \text{otherwise}.
    \end{cases}
\]
  
\end{block}



%We can avoid self-reference by considering a functional
%$G\colon (\mathbb{N} \to \mathbb{N}) \to (\mathbb{N} \to \mathbb{N})$
%defined by
%\begin{equation} \label{eq:summation}
%  (G(f))(n) \defeq
%  \begin{cases}
%     0 & \text{if } n = 0 \\
%     n + f(n - 1)  & \text{otherwise}.
%  \end{cases}
%\end{equation}
%Then, we can show that if there exists $s\colon \mathbb{N} \to \mathbb{N}$ such that $G(s) = s$ then $s = \mathit{sum}$ by induction.
\end{frame}

\begin{frame}{Curry's paradoxical combinator}
  The \emph{Y combinator} is defined as a term 
  \[
    \mathbf{Y} \defeq \lambda f.\, (\lambda x.\, f\,(x\,x))\,(\lambda
    x.\,f\,(x\,x)).
  \]
\begin{proposition}
  $\mathbf{Y}$ is a fixed-point operator, i.e.\ 
  \begin{align*}
    \mathbf{Y}F
    & \onereduce {\color{red} (\lambda x.\,F\,(x\,x))\,(\lambda x.\, F\,(x\,x))} \\
    & \onereduce F\,({\color{red}(\lambda x.\,F\,(x\,x))\,(\lambda x.\, F\,(x\,x))}) \\
  \end{align*}
  for every $\lambda$-term~$F$. In particular, $\mathbf{Y}F =_\beta F(\mathbf{Y}F)$.
\end{proposition}
Intuitively, $\mathbf{Y}F$ defines recursion where $F$ describes each iteration. 
\end{frame}


\begin{frame}{Summation via $\mathtt{Y}$}
  We encode the following recursion
  \[
    \mathit{sum}(n) =
      \begin{cases} 
       0 & \text{if } n = 0 \\
       n + \mathit{sum}(n - 1)  & \text{otherwise}.
      \end{cases}
  \]
  by generalising each iteration $G$ with an additional function $f$
  \[
    G \defeq \lambda f\,n.\, \mathtt{ifz}\;n\;\bc_0\; (\add\;n\;(f\;(\mathtt{pred}\;n)))
  \]
  so that $\mathtt{sum} \defeq \mathbf{Y}G$. For example, 
  \begin{align*}
    \mathtt{sum}\;\bc_1
      &\equiv  (\mathbf{Y}G)\;\bc_1 \\
      &\onereduce G'\;\bc_1 \\
      &\onereduce G\;G'\;\bc_1 \\
      &\onereduce (\lambda n.\, \mathtt{ifz}\;n\;\bc_0\;
      (\add\;n\;(G'\;(\mathtt{pred}\;n))))\;\bc_1 \\
      &\onereduce \mathtt{ifz}\;\bc_1\;\bc_0\;
      (\add\;\bc_1\;(G'\;(\mathtt{pred}\;\bc_1))) \\
      &\onereduce \dots
  \end{align*}
  where
  $G' \defeq ((\lambda x.\, G\;(x\;x))\;(\lambda x.\,G\;(x\;x)))$.
\end{frame}
  
\begin{frame}{Turing's fixed-point combinator}
  Recall that $\mathbf{Y}G =_\beta G(\mathbf{Y}\;G)$ but $\mathbf{Y}G \reduce
  G(\mathbf{Y}\;G)$ does not hold.  Here is a fixed-point operator such that
  $\Theta F \reduce F(\Theta F)$.
\begin{proposition}
  Define 
  \[
    \Theta \defeq 
    (\lambda x\,f.\,f\,(x\,x\,f))\;
    (\lambda x\,f.\,f\,(x\,x\,f))
  \]
  Then, 
  \[
    \Theta F \reduce F (\Theta F)
  \]
\end{proposition}
Try Turing's fixed-point combinator with $G$ to define $\sum_{i=0}^n i$.
\begin{align*}
  G \defeq{} &
  \lambda f\,n.\,
  \mathtt{ifz}\;n\;\bc_0\;
  (\add\;n\;(f\,(\mathtt{pred}\;n))) \\
  \mathtt{sum} \defeq\; & \Theta\,G 
\end{align*}
\end{frame}

\begin{frame}{Exercise}
  \begin{enumerate}
    \item Evaluate $\mathtt{sum}\;\bc_1$ to its normal form in detail.
    \item Define the factorial $n!$ with Church numerals.
  \end{enumerate}
\end{frame}


\section{Properties of $\lambda$-Calculus}

\begin{frame}
  \begin{example}
    Suppose $M \; \term_\lambda$ and $y \not\in \FV(M)$. 
    Then, consider 
    \[
      (\lambda y.\, M)\, ((\lambda x.\, x\,x)(\lambda x.\, x\, x))
    \]
  \end{example}
  \mode<presentation>{\vfill}
  Observations:
  \begin{itemize}
    \item Some evaluation may diverge while some may converge.
    \item Full $\beta$-reduction lacks for determinacy. 
  \end{itemize}
  Question:
  \begin{itemize}
    \item Does every path give the same evaluation?
  \end{itemize}
\end{frame}

\begin{frame}{Confluence}
\begin{theorem}[Church-Rosser]
  Given $N_1$ and $N_2$ with $M \reduce N_1$ and $M\reduce N_2$, there is $L$
  such that $N_1 \reduce L$ and $N_2 \reduce L$. 
  \[
    \xymatrix{
      & M \ar[rd]^{\beta*} \ar[ld]_{\beta*} \\
      N_1 \ar[rd]_{\beta*} & & N_2 \ar[ld]^{\beta*} \\
      & L
    }
  \]
\end{theorem}

No matter which way we choose we can always find a \alert{confluent}
term. 

\end{frame}

\begin{frame}{Normal form}
  \begin{definition}
    $M$ is \emph{in normal form} if 
    there is no $N$ such that $M \onereduce N$, abbreviated to $M \notonereduce$.
    
  \end{definition}
  \begin{lemma}
    Suppose that $M$ is in normal form. Then 
      $M \reduce N$ implies $M =_\alpha N$.
  \label{lem:normal-no-reduction}%
  \end{lemma}
  \begin{proof}
    By induction on the derivation $d$ of $M \reduce N$.
    \begin{enumerate}
      \item If $d$ is given by (0-step), then
        $M \reduce N$ where $M =_\alpha N$ by definition.

      \item If $d$ is given by (n+1-step), then
        $M \onereduce M'$ and $M' \reduce N$ are derivable for some $M'$. By
        assumption $M \onereduce N$ is not derivable for any $N$, so by
        contradiction the statement follows.
    \end{enumerate}
  \end{proof}

\end{frame}

\begin{frame}{Corollaries of confluence}
  \begin{corollary}[Uniqueness of normal forms]
    Let $M$ be a term with $M \reduce N_1$ and $M\reduce N_2$ where
     $N_i$'s are in normal form. Then, $N_1 =_\alpha N_2$.
    \label{coro:uniqueness-normal}%
  \end{corollary}
  

  \begin{corollary}[Computationally equal terms have a confluent term]
    If $M =_\beta N$, then there exists $L$ satisfying
  \[
    \xymatrix{
      M \ar[rd]_{\beta*} \ar@{}[rr]|{=_\beta} & & N \ar[ld]^{\beta*} \\
      & L
    }
  \]
  \label{coro:computational-meanting-confluence}
  \end{corollary}
  \begin{proof}[Proof sketch]
    By induction on the derivation of $M =_\beta N$. 
  \end{proof}

%\begin{corollary}
%  Let $=_\beta$ denote the congruence closure of $\onereduce$. 
%  \begin{enumerate}
%    \item If $M =_\beta N$, then there exists $L$ such that 
%      \[
%        M \reduce L
%        \; _{\beta*}\longleftarrow N
%      \]
%    \item If in addition $N$ is in normal form, then 
%      $M \reduce N$. 
%  \end{enumerate}
%\end{corollary}
%\begin{block}{Homework}
%  Show this corollary.
%\end{block}
\end{frame}


\begin{frame}{Homework}
  \begin{enumerate}
    \item (2.5\%) Show Corollary~\ref{coro:uniqueness-normal}
    \item (2.5\%) Show Corollary~\ref{coro:computational-meanting-confluence}.
  \end{enumerate}
\end{frame}

\appendix 
\section{Appendix: Evaluation strategy}
\begin{frame}[allowframebreaks]{Evaluation strategies}
An evaluation strategy is a procedure of selecting $\beta$-redexes
to reduce. It is a subset $\longrightarrow_{\mathrm{ev}}$ of the full
$\beta$-reduction $\onereduce$.

\begin{description}
  \item[Innermost $\beta$-redex] does not contain any $\beta$-redex.
  \item[Outermost $\beta$-redex] is not contained in any other $\beta$-redex.
\end{description}

\begin{description}
  \item[the leftmost-outermost (\emph{normal order}) strategy] reduces the leftmost outermost
    $\beta$-redex in a term first. For example, 
    \begin{align*}
      & 
      \underline{(\lambda x.\, (\lambda y.\, y)\,x)}\quad
      \underline{(\lambda x.\, (\lambda y.\, y\,y)\,x)}
      \\
      \onereduce &
      \underline{(\lambda y.\, y)}\quad
      \underline{(\lambda x.\, (\lambda y.\, y\,y)\, x)} \\
      \onereduce &
      \lambda x.\, \underline{(\lambda y.\, y\,y)}\quad
      \underline{\vphantom{(\lambda}x} \\
      \onereduce & (\lambda x.\, x\,x) \\
      \notonereduce
    \end{align*}
  \item[the leftmost-innermost strategy] reduces the leftmost innermost
    $\beta$-redex in a term first. For example, 
    \begin{align*}
      & (\lambda x.\, \underline{(\lambda y.\,
        y)}\;\;\underline{\vphantom{(\lambda} x})\,
      (\lambda x.\, (\lambda y.\, y\, y)\,x) \\
      \onereduce & (\lambda x.\,x)\;
      (\lambda x.\, \underline{(\lambda y.\, y\,
        y)}\;\;\underline{\vphantom{(\lambda}x}) \\
      \onereduce & \underline{(\lambda x.\,x)}\;\;\underline{(\lambda x.\, x\,x)} \\
      \onereduce & (\lambda x.\, x\, x) \\
      \notonereduce
    \end{align*}
  \item[the rightmost-innermost/outermost strategy]
    are defined similarly where terms are reduced from right to left
    instead.
\end{description}
\end{frame}

\begin{frame}{CBV versus CBN}
\begin{description}
  \item[Call-by-value strategy]
    rightmost-outermost but not under any abstraction
  \item[Call-by-name strategy]
    leftmost-outermost but not under any abstraction
\end{description}

  \mode<presentation>{\vfill}
\begin{proposition}[Determinacy]
  Each of evaluation strategies is deterministic, i.e.\ 
  if $M \onereduce N_1$ and $M \onereduce N_2$ then $N_1 = N_2$.
\end{proposition}
\end{frame}

\begin{frame}{Exercise}
  Define following terms
\begin{align*}
  \Omega &\defeq (\lambda x.\, x\,x)\;(\lambda x.\,x\,x) \\
  \mathbf{K}_1 & \defeq \lambda x\,y.\;x
\end{align*}
Evaluate 
\[
  \mathbf{K}_1\;z\;\Omega
\]
using the call-by-value and the call-by-name strategy respectively.
\end{frame}

\begin{frame}{Normalisation}
\begin{definition}
  \begin{enumerate}
    \item $M$ is in \emph{normal form} if $M \notonereduce N$ for any $N$. 
    \item $M$ is \emph{weakly normalising} if $M \reduce N$ for some $N$ in
      normal form.
  \end{enumerate}
\end{definition}
%
  \begin{enumerate}
    \item $\Omega$ is not weakly normalising.
    \item $\mathbf{K}_1$ is normal and thus weakly normalising.
    \item $\mathbf{K}_1\;z\; \Omega$ is weakly normalising.
  \end{enumerate}

\begin{theorem}
  The normal order strategy reduces every weakly
  normalising term to a normal form.
\end{theorem}

\end{frame}
%\begin{frame}{Remark}
% The definition of capture-avoiding substation is widely adopted, it is still
% ill-defined.  Recursion is always a total function. Advanced
% mathematics~\cite{Pitts2013} is needed to resolve this issue.
%
%  \mode<presentation>{\vfill}
% Issues with named variables may be lifted by using nameless representation of
% terms. For example, in de Bruijin's representation every term 
% has a canonical form, see \cite[Chapter 6]{Pierce2002}.
%
%  \mode<presentation>{\vfill}
%  In fact, every computable function on natural numbers is definable in terms of
%  terms. For interested readers, see~\cite[Chapter 3]{Barendregt1984}
%  for further detail. Therefore, $\lambda$-calculus is Turing-complete. 
%\end{frame}


%\begin{frame}[allowframebreaks]{References}
%  \bibliographystyle{amsalpha}
%  \bibliography{library} 
%\end{frame}

\end{document}
